---
title: "Sharing Open COVID-19 Data with the COVIDcast API"
author: "Alex Reinhart and Kathryn Mazaitis"
date: 2020-09-02
tags: ["COVIDcast API", "packages", "COVIDcast"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

We make our COVIDcast API freely available to
the community. Containing numerous COVID-19 data streams, including some
exclusively available from Delphi's partners in technology and healthcare, the
COVIDcast API provides researchers and decision-makers with the data they need
to conduct their work.

<!--more-->

In 2012, we formed Delphi to “develop the theory and practice of epidemic
forecasting, and its role in decision-making.” Led by Roni Rosenfeld and Ryan
Tibshirani, with several participating faculty and graduate students, we
participated in annual CDC flu forecasting challenges starting in 2013, earning
top placements in several. We were named a CDC Center of Excellence for flu
forecasting in 2019. Throughout our history, we have been dedicated to  making
our code and data available to the public, including numerous influenza
surveillance streams.

This policy continues with our COVIDcast API, which we make freely available to
the community. Containing numerous COVID-19 data streams, including some
exclusively available from Delphi's partners in technology and healthcare, the
COVIDcast API provides researchers and decision-makers with the data they need
to conduct their work.

## The purpose of the API

The COVID-19 pandemic is so hard a problem that our best weapon is a diversity
of data sources. This caused a shift in Delphi's attention: before we could
build forecasts, we needed to rapidly develop relevant data streams. This effort
became the COVIDcast project.

The COVIDcast project has many parts:

* Unique relationships with partners in tech and healthcare granting us to access to data on pandemic activity
* Code and infrastructure to build COVID-19 indicators, continuously-updated and geographically comprehensive within the USA
* A historical database of all indicators, including revision tracking, with over 500 million observations to-date
* [A public API](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html) serving new indicators daily, with [R and Python packages](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_clients.html) for client support
* [Interactive maps and graphics](https://covidcast.cmu.edu/) to display our indicators
* Forecasting and modeling work building on the indicators

The data streams we are interested in can be roughly mapped to the epidemic
severity pyramid, which matches the progression of disease in the population:

1. The **population**'s behavior, mobility, and attitudes affect disease
   transmission
2. Some are **infected**
3. Some infected people show **symptoms**
4. Some people with symptoms seek **outpatient medical care**
5. Confirmed cases are then **ascertained**, when test results or clinical
   diagnoses are completed
6. Some patients are **hospitalized**
7. Finally, **deaths** due to the illness are recorded.

Each level of the pyramid can be examined using different data sources. For
example, cell phone mobility data could address population behavior, while
volume of certain search queries might correlate with how many people have
symptoms. Levels 4 through 7 of the pyramid are medically attended, and so can
be examined using medical records of various kinds; confirmed cases and deaths
are also reported through local and state health authorities.

As we move from level 1 to level 7, the data become more specific, since each
level includes fewer and fewer people. The data also become less timely: level 1
can be a *leading indicator* of illness, since behavior can predict spread, but
level 7 data only occurs after patients have already been infected and died. But
only at level 5 do we actually gain data about diagnoses -- data before level 5
is "syndromic", meaning it can only relate to symptoms and behaviors.

Data streams that are organized in this way can be used for many possible purposes, including:

* Forecasting, e.g. case incidence (for vaccine trial site selection) and hospitalizations (for planning and preparedness)
* Nowcasting, e.g. situational awareness (for testing and resource allocation) and decision-making (for re-opening criteria, closures, and cancellations)
* General epidemiological research, e.g. what behaviors are linked to spread? What symptoms are linked to cases?

## Our unique data sources

Delphi has leveraged its history and reputation in influenza forecasting to
secure several sources of pandemic data that are unavailable anywhere else.
Agreements with our partners permit us to publish aggregated data, and these
data streams are included in the COVIDcast API. These data sources cover most
levels of the severity pyramid, and include:

* [Massive surveys we conduct through
  Facebook](https://covidcast.cmu.edu/surveys.html): Facebook has been sending a
  random sample of its users to Delphi's symptoms and behavior survey every day
  since April 6. We average 70,000 responses each day, making this survey, and
  its [international sister survey](https://covidmap.umd.edu/) run by University
  of Maryland, the largest public health survey ever conducted. We wrote about
  the survey in a [previous blog
  post](https://delphi.cmu.edu/blog/2020/08/26/covid-19-symptom-surveys-through-facebook/),
  and more details, including a full list of questions, are available in [our
  documentation](https://cmu-delphi.github.io/delphi-epidata/symptom-survey/).
* [Large surveys through
  Google](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/google-survey.html):
  From April 11 to May 14, Delphi conducted a single-question symptoms survey
  through Google. It reached 100,000 respondents daily during its short run, and
  was a surprisingly effective measure of pandemic activity preceding medical
  contact.
* [Google search
  trends](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/ght.html):
  We query the Google Health Trends API for overall searcher interest in a set
  of COVID-19 related terms about anosmia (loss of smell or taste), which
  emerged as a symptom of the coronavirus. More details, including the specific
  search terms and topics we analyze, are available in [our
  documentation](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/ght.html#estimation).
* Medical records: Electronic medical records include diagnostic codes,
  complaint notes, and lab results which can be used to estimate COVID-19
  activity in a region. We have several partners who provide us with these
  records, strictly de-identified to protect privacy.
* Insurance claims: Medical insurance claims include diagnostic codes, lab
  orders, and charge codes which can be used to estimate COVID-19 activity in a
  region. We have several partners who provide us with aggregate and line-level
  claims data, strictly de-identified to protect privacy. We use this data to
  construct signals reflecting COVID activity in [outpatient doctor's
  visits](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/doctor-visits.html)
  and in [hospital
  admissions](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/hospital-admissions.html).
* [Quidel COVID antigen
  tests](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/quidel.html#covid-19-tests):
  Quidel is a national provider of networked lab testing devices, and began
  making de-identified records on COVID-19 antigen tests available to us in
  early May. Testing volume grew to statistically meaningful levels in July,
  with backfilled records meeting our thresholds going back to May 26th.

We also host the following more widely-available signals in our API for the
convenience of the forecasting community and to provide revision tracking:

* Confirmed cases and deaths as [reported by JHU CSSE](https://github.com/CSSEGISandData/COVID-19)
* Confirmed cases and deaths as [reported by USAFacts](https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/)
* [SafeGraph mobility
  data](https://docs.safegraph.com/docs/social-distancing-metrics); SafeGraph
  makes detailed data available to researchers, and by agreement with SafeGraph,
  we make county-level aggregates publicly available

Nearly all our data streams are available at the county level across the United
States. We also aggregate most signals to metropolitan statistical areas and
states. For a full list of all data streams, see the [COVIDcast signal
documentation](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_signals.html).

All of the above data streams are made publicly available through our COVIDcast
API -- if you're interested in using these signals for research or to understand
trends in your area, pulling the data is only a moment's work. Let's discuss how
the data is stored and how you can get access.


## The data schema

Each record in our API is an observation covering a set of events aggregated by time and by region. Most signals in the API aggregate daily, but some aggregate weekly, so we tend to keep the official definitions general. Each observation thus includes:

* `time_value`: The time period when the events occurred
* `geo_value`: The geographic region where the events occurred
* `value`: The aggregate value
* `stderr`: The standard error
* `sample_size`: The number of events making up the aggregation
* `issue`: The time period when this observation became known / was published
* `lag`: The time delay between when the events occurred and when this observation was published

For example, a number of COVID-19 antigen tests were performed in the state of
New York on August 1. Information about those tests might take between four days
and six weeks to reach us, depending on the technology and staff available at
each testing site. We publish our first estimate for August 1st's test
positivity rate (the percentage of tests that were positive for COVID-19) in the
state of New York on August 6th. When more data about August 1st's tests arrive
the next day, we issue a new estimate. This continues over subsequent days,
refining the estimate over time:

```{r q-versioning, warning=FALSE, message=FALSE, cache=TRUE}
library(covidcast)
library(dplyr)
query_date <- "2020-08-01"
covidcast_signal(
  data_source = "quidel",
  signal = "covid_ag_raw_pct_positive",
  start_day = query_date,
  end_day = query_date,
  geo_type = "state",
  geo_value = "ny",
  issues = c(query_date, "2020-09-04")) %>%
    select(time_value, value, issue, lag) %>%
    distinct(value, .keep_all=TRUE) %>%
    knitr::kable("html", digits = 2,
                 col.names = c("Test date", "Positivity rate (%)", "Issued on", "Lag (days)"))
```

Many other data sources are also subject to revisions:

* Case and death counts are frequently corrected or adjusted by authorities
* Medical claims data can take weeks to be submitted and processed
* Lab tests and medical records can be backlogged for a variety of reasons
* Surveys are not always completed promptly

An accurate revision log is crucial for researchers building forecasts of
COVID-19 cases or outcomes. A forecast that is made today can only rely on
information we have access to today. Forecasting models are often developed by
building them to predict cases using historical data -- but to do so, the model
must use only data that was available on the forecast date, not the updates that
would only arrive later. We track all revisions to all data sources we ingest,
allowing users to request the data as it was known on a specific date.

## The clients and their features

A massive database of COVID-19 data is, of course, of no use if nobody can get
access to it. We make the COVIDcast API available publicly with no registration
required; users can simply make requests to a specific query URL and receive
data back in JSON form. Query syntax is defined on our [API documentation
site](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html).

We also provide R and Python packages to make access to the data easy for anyone
already conducting data analysis in either language. For example, an R user can
install our [covidcast
package](https://cmu-delphi.github.io/covidcast/covidcastR/) and then quickly
plot the percentage of hospital admissions are due to COVID-19 in several
states. (Click the Code button to see full code.)

```{r dv-graph, message=FALSE, cache=TRUE}
library(covidcast)
hosp <- covidcast_signal(
    data_source = "hospital-admissions", signal = "smoothed_adj_covid19",
    start_day = "2020-03-01", end_day = "2020-08-30",
    geo_type = "state", geo_values = c("pa", "ny", "tx")
)

plot(hosp, plot_type = "line",
     title = "% of hospital admissions due to COVID-19")
```

Since the packages also support mapping, we can also examine, say, the
percentage of outpatient doctor visits due to COVID-like illnesses in the south:

```{r dv-maps, message=FALSE, cache=TRUE, fig.width=10}
library(gridExtra)
dv <- covidcast_signal(
    data_source = "doctor-visits", signal = "smoothed_adj_cli",
    start_day = "2020-07-15", end_day = "2020-08-24")

south <- c("md", "de", "va", "wv", "ky", "tn", "nc", "sc", "fl", "ga", "al",
           "ms", "la", "ar", "tx", "ok")
g1 <- plot(dv, time_value = "2020-07-15", include = south,
           title = "% of doctor's visits due to CLI on July 15")

g2 <- plot(dv, time_value = "2020-08-24", include = south,
           title = "% of doctor's visits due to CLI on Aug 24")

grid.arrange(g1, g2, nrow = 1)
```

In Python, fetching data requires the [covidcast
package](https://cmu-delphi.github.io/covidcast/covidcast-py/html/), which can
quickly produce a Pandas data frame. For example, here we fetch the estimated
percentage of people in each state who know someone who is sick, based on
Delphi's [symptom
surveys](https://delphi.cmu.edu/blog/2020/08/26/covid-19-symptom-surveys-through-facebook/).
(Again, click Code to see the code required to produce this example.)

```{python python-data, dev='svg'}
import covidcast
from datetime import date
import matplotlib.pyplot as plt
data = covidcast.signal("fb-survey", "smoothed_hh_cmnty_cli",
                        date(2020, 9, 8), date(2020, 9, 8),
                        geo_type="state")
covidcast.plot_choropleth(data, figsize=(12, 10))
plt.title("% who know someone who is sick, Sept 8, 2020")
```

Each package's documentation gives numerous other examples of pulling, plotting,
and mapping data from our API.

## How a dataset becomes an indicator

Now that we've seen how easy it is to get data from the COVIDcast API, let's see
how data gets into the API in the first place. The following general
extract-transform-load procedure is used by all COVIDcast indicators.

First, our custom code (slated to be released open-source later this fall) does
the following:

1. Download data from the source. This could be via an API query, scraping a
   website, an SFTP dropbox, or an email attachment.
2. Process the source data to extract one or more signals. A signal includes a
   value, standard error, and sample size for each region on each unit of time.
3. Aggregate each signal to higher geographic levels. For example, we generate
   data at the state level by combining data at the county level.
4. Format each signal into a set of CSV files with a fixed format, and deliver
   those files to a drop-off directory on our API server.

Different sources publish their data at different times of day, so to minimize
lag, each indicator is run as soon as new files become available.

Picking up the next phase of the ETL procedure, once an hour, our
[delphi-epidata codebase](https://github.com/cmu-delphi/delphi-epidata) does the
following:

1. Look in the drop-off folder to see if any new data files are available. If there are, then:
2. Import the new data into the covidcast table of the epidata database, filling
   in the columns as follows:
   - source: parsed from the name of the subdirectory of the drop-off folder
   - signal: parsed from the filename
   - time_type: parsed from the filename
   - time_value: parsed from the filename
   - geo_type: parsed from the filename
   - geo_value: parsed from each row of the csv file
   - value: parsed from each row of the csv file
   - se: parsed from each row of the csv file
   - sample_size: parsed from each row of the csv file
   - issue: whatever now is in time_type units
   - lag: the difference in time_type units from now to time_value
   - value_updated_timestamp: now
   - direction_updated_timestamp: null
3. Update the is_latest_issue column of the just-added rows and the
   previously-latest rows.
4. Update the metadata cache: For every (source, signal, time_type, geo_type)
   tuple, compute the minimum and maximum time_value, value, issue, and lag, the
   number of regions with data, and the total mean and stdev, and cache them in
   a JSON string.

## Conclude somehow

The COVIDcast API provides unified access to numerous COVID data streams, which
can be browsed with an [interactive map](https://covidcast.cmu.edu/) and easily
accessed through R and Python packages. Unlike most other sources of COVID data,
it tracks the complete revision history of every signal, allowing historical
reconstructions of what information was available at specific times. And many of
its data streams simply aren't available anywhere else.

We invite you to put the API to use for your own purposes. Building a dashboard
for your community? Testing out forecasting methods? Studying how the pandemic
evolves? We have data that could be useful for you.

Many of our data streams are already being used to inform decision-making. For
example, [COVID Exit Strategy](https://www.covidexitstrategy.org/) tracks the
pandemic and whether states are ready to reopen, and uses symptom survey data
from the COVIDcast API as a key data source. Anthem's [C19
Explorer](https://c19explorer.io/) presents a comprehensive community picture of
the pandemic, using outpatient doctor's visit data from COVIDcast. Aledade's
[COVID-19 Interactive Map](https://covidmap.aledade.com/) applies scan
statistics algorithms to COVIDcast survey data to detect statistically
significant clusters.

We hope to see you join this list soon!

## I wrote up this glossary for Engineering onboarding; should we include it here?

* indicator - a loose term variously referring to a single data stream, or to a set of data streams sharing some characteristics. For example, "the combination indicator" typically refers to the `nmf_day_doc_fbc_fbs_ght` signal currently shown in the COVIDcast map; "the JHU indicator" typically refers to all signals generated using the cases and deaths data published by Johns Hopkins University's Center for Systems Science and Engineering
* source - for most indicators, this is the name of the organization that provided the source dataset. This includes `jhu-csse`, `safegraph`, and `quidel`. Exceptions: The source data for `doctor-visits` and `hospital-admissions` is provided to us by health system partners who wish to remain uncredited. The source data for `indicator-combination` comes from our own API.
* signal - In technical conversations, this means a single metric under a single configuration. For example, in doctor-visits, `smoothed_cli` and `smoothed_adj_cli` both measure COVID-like illness, but one of them is transformed to remove weekday variations. They are separate signals. More casually, we sometimes talk about e.g. "the community CLI signal" from fb-survey, even though four variations are available (raw vs smoothed; weighted vs unweighted). Even more casually, 'signal' is sometimes used as a synonym for 'indicator', e.g. "the cases and deaths signal".
* geo level, geo type, regional level - usually one of: state, county (fips), hospital referral region (hrr), metropolitan statistical area (metro area; msa), designated market area (dma).
* geo id, region id - an alphanumeric code identifying a particular state, county, hrr, msa, or dma. For example, the geo id of a state might be 'pa', 'ca', 'oh', 'pr'; the geo id of a county might be '15215', '02492', '94301'.
* issue - like a magazine issue; a collection of data that was published together. For daily signals, the issue date is a day. For weekly signals, the issue date is an epidemiological week ("epiweek"). In COVIDcast we use a diff-based issue that includes only the rows that changed during the time period covered by the issue. Rows that stayed the same are not explicitly confirmed. Rows that were removed are not currently distinguished from rows that stayed the same; this will be addressed in a missingness encoding scheme under development.

**Credits.** *The COVIDcast API builds on the Epidata API, built by Delphi
founding member David Farrow. Kathryn Mazaitis leads Delphi's engineering team.
Brian Clark manages the API infrastructure, with significant help from Wael Al
Saeed, George Haff, Eu Jing Chua, and Samuel Gratzl. Alex Reinhart maintains the
COVIDcast API clients, with major contributions from Ryan Tibshirani and Andrew
Chin. Ryan Tibshirani and Roni Rosenfeld secured many data partnerships, with
significant support from CMU's legal team. Many Delphi team members contributed
code and expertise to ingest and serve data for the COVIDcast API, including 
Aaron Rumack, Addison Hu, Eu Jing Chua, James Sharpnack, Jeremy Weiss, Jimi Kim,
Jingjing Tang, Sangwon Hyun, Larry Wasserman, Lester Mackey, Logan Brooks, Maria
Jahja, Natalia Lombardi de Oliveira, Noah Simon, Pratik Patil, Robert
Tibshirani, Roni Rosenfeld, Samyak Rajanala, Valérie Ventura, and Zachary
Lipton.*

---

*[Alex Reinhart](https://www.refsmmat.com) manages Delphi's surveys, and is an
Assistant Teaching Professor in the Department of Statistics & Data Science at
CMU.*

*[Kathryn Mazaitis](https://cs.cmu.edu/~krivard) leads Delphi's
engineering team, and is a Senior Research Programmer in the Machine
Learning Department at CMU.*
