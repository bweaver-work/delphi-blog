---
title: "COVIDcast Data API"
author: "Alex Reinhart and Kathryn Mazaitis"
date: 2015-09-07
tags: ["COVIDcast API", "packages"]
draft: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

A teaser paragraph about the API

<!--more-->

## Our open source philosophy

In 2012, we formed Delphi to “develop the theory and practice of epidemic forecasting, and its role in decision-making.” Led by Roni Rosenfeld and Ryan Tibshirani, with several participating faculty and graduate students, we participated in annual CDC flu forecasting challenges starting in 2013, earning top placements in several. We were named a CDC Center of Excellence for flu forecasting in 2019. Throughout our _, we have been dedicated to  making our code and data available to the public, including numerous influenza surveillance streams. This policy continues with our COVIDcast API.

## The purpose of the API

The COVID-19 pandemic is so hard a problem that our best weapon is a diversity of data sources. This caused a shift in Delphi's attention: before adequate forecasting could take place, we needed to rapidly develop relevant data streams. This effort became the COVIDcast project.

The COVIDcast project has many parts:
* Unique relationships with partners in tech and healthcare granting us to access to data on pandemic activity
* Code and infrastructure to build COVID-19 indicators, continuously-updated and geographically comprehensive within the USA
* A historical database of all indicators, including revision tracking, with over 500 million observations to-date
* A public API serving new indicators daily, with R and Python packages for client support
* Interactive maps and graphics to display our indicators
* Forecasting and modeling work building on the indicators

The data streams we are interested in can be roughly mapped to the severity pyramid [citation needed]. For example:

1. General population: public behavior, mobility, and attitudes
2. Infected: 
3. Symptomatic: web searches, symptoms surveys
4. Outpatient visit: medical records, insurance claims
5. Ascertained (confirmed case): public health reports, lab test reports
6. Hospitalized and ICU: medical records, insurance claims, public health reports
7. Dead: public health reports

The closer to 1, the earlier or more leading the indicator; the closer to 7, the later or more lagging the indicator. As we move from level 1 to level 7, the data get more specific, as the pool of people included in that level grows smaller, and we become more and more confident that they are actually suffering from COVID-19 and not some other disease.

Levels 4-7 are medically attended, and can take advantage of electronic medical records of various kinds. 

Before test results become available at level 5, indicators cannot provide true case data; any symptom data they can provide is considered "syndromic".

Data streams that are organized in this way can be used for many possible purposes, including:

* Forecasting, e.g. case incidence (for vaccine trial site selection) and hospitalizations (for planning and preparedness)
* Nowcasting, e.g. situational awareness (for testing and resource allocation) and decision-making (for re-opening criteria, closures, and cancellations)
* General epidemiological research, e.g. what behaviors are linked to spread? What symptoms are linked to cases?

## Our unique data sources

Delphi has leveraged its history and reputation in influenza forecasting to secure several sources of pandemic data which are unavailable anywhere else. Our DUAs permit us to publish aggregated data which is useful to forecasting, and these data streams are included in the COVIDcast API.

* Massive surveys through Facebook - General population; Symptomatic - Facebook has been sending a random sample of its users to Delphi's symptoms and behavior survey since April 6. We average 70k responses each day, making this survey, and its international sister survey run by University of Maryland, the largest public health survey ever _ed. More details, including a full list of questions, are available in our documentation [link needed].
* Large surveys through Google - Symptomatic - From [start] to [end], Delphi conducted a single-question symptoms survey through Google [product]. It reached [count] respondents, and was a surprisingly effective measure of pandemic activity preceding medical contact. 
* Google search trends - Symptomatic - We query the Google Health Trends API for overall searcher interest in a set of COVID-19 related terms about anosmia (lack of smell or taste), which emerged as a symptom of the coronavirus. More details, including the specific search terms and topics we analyze, are available in our documentation [link needed].
* Medical records - Outpatient visit; Hospitalized; ICU - Electronic medical records include diagnostic codes, complaint notes, and lab results which can be used to estimate COVID-19 activity in a region. We have several partners who provide us with these records, strictly de-identified to protect privacy.
* Insurance claims - Outpatient visit; Hospitalized; ICU - Medical insurance claims include diagnostic codes, lab orders, and charge codes which can be used to estimate COVID-19 activity in a region. We have several partners who provide us with aggregate and line-level claims data, strictly de-identified to protect privacy.
* Quidel antigen tests - Ascertained - Quidel is a national provider of networked lab testing devices, and began _ us with   de-identified records on COVID-19 antigen tests in early May. Testing volume grew to statistically meaningful levels in July, with backfilled records meeting our thresholds going back to May 26th.

All of the above are available through the COVIDcast API and updated daily. We also host the following more widely-available signals for the convenience of the forecasting community and to provide revision tracking:

* JHU CSSE confirmed cases and deaths
* USAFacts confirmed cases and deaths
* SafeGraph mobility data

Nearly all data streams are available at the county level.

For a full list of all data streams, see the COVIDcast documentation [link].

## The data schema

Each record in the API is an observation covering a set of events aggregated by time and by region. Most signals in the API aggregate daily, but some aggregate weekly, so we tend to keep the official definitions general. Each observation thus includes:

* `time_value` - The time period when the events occurred
* `geo_value` - The geographic region where the events occurred
* `value` - The aggregate value
* `stderr` - The standard error
* `sample_size` - The number of events making up the aggregation
* `issue` - The time period when this observation became known / was published
* `lag` - The time delay between when the events occurred and when this observation was published

For example, a number of COVID-19 antigen tests were performed in Pittsburgh, PA on June 1. Depending on the testing site, information about those tests might take between four days and six weeks to reach us, depending on the technology and staff available at each site. We publish our first estimate for June 1st's percent test positivity rate in Pittsburgh on June 5. When more data about June 1st's tests arrive the next day, we issue a new estimate. This continues over subsequent days, refining the estimate over time.

[table]

Many other data sources are also subject to revisions:
* Case and death counts are frequently corrected/adjusted by authorities
* Medical claims data can take weeks to be submitted and/or processed
* Lab tests and medical records can be backlogged for a variety of reasons
* Surveys are not always completed promptly

An accurate revision log is crucial for forecasting. A forecast that is made today can only rely on information we have access to today. When a forecaster is trained, it must be given data that was accessible on the forecast date, not the updates that would arrive later.

## The clients and their features

## How a dataset becomes an indicator

This is the general extract-transform-load procedure used by all COVIDcast indicators.

First, an indicator module in the covidcast-indicators codebase (currently closed-source; slated to be released open-source later this fall) does the following:

1. Download data from the source. This could be via an API query, scraping a website, an SFTP dropbox, or an email attachment.
2. Process the source data to extract one or more signals. A signal includes a value, standard error, and sample size for each region on each unit of time (a day, or an epidemiological week "epiweek").
3. Aggregate each signal to higher geographic levels. For example, we generate data at the state level by combining data at the county level.
4. Format each signal into a set of CSV files with a fixed format, and deliver those files to a drop-off directory on the API server.

Different sources publish their data at different times of day, so to minimize lag, each indicator is run as soon as new files become available.

Picking up the next phase of the ETL procedure, once an hour, the acquisition:covidcast component of the delphi-epidata codebase [link] does the following:

1. Look in the drop-off folder to see if any new data files are available. If there are, then:
2. Import the new data into the covidcast table of the epidata database, filling in the columns as follows:
- source: parsed from the name of the subdirectory of receiving/
- signal: parsed from the filename
- time_type: parsed from the filename
- time_value: parsed from the filename
- geo_type: parsed from the filename
- geo_value: parsed from each row of the csv file
- value: parsed from each row of the csv file
- se: parsed from each row of the csv file
- sample_size: parsed from each row of the csv file
- issue: whatever now is in time_type units
- lag: the difference in time_type units from now to time_value
- value_updated_timestamp: now
- direction_updated_timestamp: null
3. Update the is_latest_issue column of the just-added rows and the previously-latest rows.
4. Update the metadata cache: For every (source, signal, time_type, geo_type) tuple, compute the minimum and maximum time_value, value, issue, and lag, the number of regions with data, and the total mean and stdev, and cache them in a JSON string.


## A short note on Epidata history
## Conclude somehow


## I wrote up this glossary for Engineering onboarding; should we include it here?

* indicator - a loose term variously referring to a single data stream, or to a set of data streams sharing some characteristics. For example, "the combination indicator" typically refers to the `nmf_day_doc_fbc_fbs_ght` signal currently shown in the COVIDcast map; "the JHU indicator" typically refers to all signals generated using the cases and deaths data published by Johns Hopkins University's Center for Systems Science and Engineering
* source - for most indicators, this is the name of the organization that provided the source dataset. This includes `jhu-csse`, `safegraph`, and `quidel`. Exceptions: The source data for `doctor-visits` and `hospital-admissions` is provided to us by health system partners who wish to remain uncredited. The source data for `indicator-combination` comes from our own API.
* signal - In technical conversations, this means a single metric under a single configuration. For example, in doctor-visits, `smoothed_cli` and `smoothed_adj_cli` both measure COVID-like illness, but one of them is transformed to remove weekday variations. They are separate signals. More casually, we sometimes talk about e.g. "the community CLI signal" from fb-survey, even though four variations are available (raw vs smoothed; weighted vs unweighted). Even more casually, 'signal' is sometimes used as a synonym for 'indicator', e.g. "the cases and deaths signal".
* geo level, geo type, regional level - usually one of: state, county (fips), hospital referral region (hrr), metropolitan statistical area (metro area; msa), designated market area (dma).
* geo id, region id - an alphanumeric code identifying a particular state, county, hrr, msa, or dma. For example, the geo id of a state might be 'pa', 'ca', 'oh'; the geo id of a county might be '15215', '02492', '94301'.
* issue - like a magazine issue; a collection of data that was published together. For daily signals, the issue date is a day. For weekly signals, the issue date is an epidemiological week ("epiweek"). In COVIDcast we use a diff-based issue that includes only the rows that changed during the time period covered by the issue. Rows that stayed the same are not explicitly confirmed. Rows that were removed are not currently distinguished from rows that stayed the same; this will be addressed in a missingness encoding scheme TBD.

---


*[Alex Reinhart](https://www.refsmmat.com) manages Delphi's surveys, and is an
Assistant Teaching Professor in the Department of Statistics & Data Science at
CMU.*

*[Kathryn Mazaitis](https://cs.cmu.edu/~krivard) leads Delphi's
engineering team, and is a Senior Research Programmer in the Machine
Learning Department at CMU.*

---

Remaining template content for instructive purposes:

You can embed an R code chunk like this:

```{r cars}
summary(cars)
fit <- lm(dist ~ speed, data = cars)
fit
```

## Including Plots

You can also embed plots. See Figure \@ref(fig:pie) for example:

```{r pie, fig.cap='A fancy pie chart.', tidy=FALSE}
par(mar = c(0, 1, 0, 1))
pie(
  c(280, 60, 20),
  c('Sky', 'Sunny side of pyramid', 'Shady side of pyramid'),
  col = c('#0292D8', '#F7EA39', '#C4B632'),
  init.angle = -50, border = NA
)
```

For posts where we're using our public data and showing it off, including some
of the code chunks would be great so that readers see how easy it is to use our
data. But for other audiences, it's probably best to use the `echo=FALSE` chunk
option so the code is not included in the post.

## Including Math

You can embed mathematics by using dollar signs for inline math and double
dollars for display math: $x = \sum_{i=1}^n i$,

$$
\frac{-b \pm \sqrt{b^2 - 4ac}}{2a}
$$

## Metadata

Each post has a title, author, date, and tags. The `draft` attribute marks a
post that should not be included in the rendered and published site, such as
this one. Choose bold, active titles, like "Delphi releases new survey data",
rather than boring titles like "New survey aggregates".

The author metadata should credit the post author or authors; as shown at the
end of this example post, you should also include a block about the authors and
linking to their home pages. But in the post text, you should also generously
name anyone who helped with parts of your post, e.g. the team members who
obtained data or set up a server or developed a package you use.

### Tags

Each post can be tagged, as you can see in the metadata block at the top. I
suggest we consider the following tags as base tags:

* forecasting
* symptom surveys
* COVIDcast API
* COVIDcast map
* nowcasting
* data sources
* news (for announcements of new features, new models, etc.)
* packages (for R and Python packages)

---

*[Frida Gomam](https://example.com) is a member of the Delphi group and a Ph.D.
student in data wrangling at the University of Southern North Dakota at Hoople.*
