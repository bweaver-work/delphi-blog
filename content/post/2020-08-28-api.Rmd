---
title: "Sharing Open COVID-19 Data with the COVIDcast API"
author: "Kathryn Mazaitis and Alex Reinhart"
date: 2020-09-02
tags: ["COVIDcast API", "packages", "COVIDcast"]
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

One of our primary initiatives at the Delphi COVIDcast project
has been to curate a diverse set of COVID-related data streams,
and to make them freely available through our
[COVIDcast API](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html).
These signals include both novel signals that we have collected, 
such as the [Facebook](https://delphi.cmu.edu/blog/2020/08/26/covid-19-symptom-surveys-through-facebook/) 
and [Google](https://delphi.cmu.edu/blog/2020/09/18/covid-19-symptom-surveys-through-google/) symptoms surveys,
% of doctor's visits due to COVID-like illness, 
and results from Quidel's antigen tests;
and also familiar signals, such as the confirmed case counts
and deaths reported by Johns Hopkins University.
The COVIDcast API provides researchers and decision-makers
with the data they need to conduct their work---for free!---and
is conveniently accessible via easy-to-use [Python](https://cmu-delphi.github.io/covidcast/covidcast-py/html/)
and [R](https://cmu-delphi.github.io/covidcast/covidcastR/) packages.

<!--more-->

One of our primary initiatives at the Delphi COVIDcast project 
([learn more about our organization here](https://delphi.cmu.edu/blog/2020/08/10/hello-world/))
has been to curate a diverse set of COVID-related data streams, 
and to make them freely available through our 
[COVIDcast API](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html).
These signals include both novel signals that we have collected, 
such as the [Facebook](https://delphi.cmu.edu/blog/2020/08/26/covid-19-symptom-surveys-through-facebook/)
and [Google](https://delphi.cmu.edu/blog/2020/09/18/covid-19-symptom-surveys-through-google/)
symptoms surveys, % of doctor's visits due to COVID-like illness, 
and results from Quidel's antigen tests; 
and also familiar signals, such as the confirmed case counts 
and deaths reported by Johns Hopkins University. 
The COVIDcast API provides researchers and decision-makers 
with the data they need to conduct their work---for free!---and 
is conveniently accessible via easy-to-use 
[Python](https://cmu-delphi.github.io/covidcast/covidcast-py/html/) 
and [R](https://cmu-delphi.github.io/covidcast/covidcastR/) packages.

Since the quaint pre-COVID years, 
when our group worked primarily on flu forecasting,
we have always made our code and data available to the public, 
creating the [Epidata API](https://cmu-delphi.github.io/delphi-epidata/) 
initially to share data from our numerous influenza surveillance streams.

We have redoubled this commitment in our COVID-19 response efforts,
launching the COVIDcast API. 
Containing numerous COVID-19 data streams, 
including a number of exclusive signals 
that we have either collected together with technology partners (e.g., symptoms surveys),
and other that we have extracted in collaboration with healthcare partners (e.g., doctor's visits), 
the COVIDcast API aims to provide researchers and decision-makers 
with the data they need to do their jobs effectively.

## Purpose of the API

Making sense of the COVID-19 pandemic can be a frustratingly hard problem
in part because each signal only tells part of the story.
Case counts are important, but different states 
use different reporting criteria
and testing availability varies.
Deaths are more accurately observed, 
but by then it may be too late.
We recognized early on that to make headway,
we require a diversity of data sources. 
This recognition caused us to shift priorities.
Before we could build forecasts and other statistical models,
we needed to rapidly develop new relevant data streams. 
This effort grew into the COVIDcast project---see our [introductory
post](https://delphi.cmu.edu/blog/2020/08/10/hello-world/) 
for more about our efforts since March.

The data streams that we work with can be roughly mapped
onto the epidemic severity pyramid,
which follows the progression of disease:

1. The population's **behavior, mobility, and attitudes** affect disease transmission.
2. Some are **infected**.
3. Some infected people show **symptoms**.
4. Some people with symptoms seek **outpatient medical care**.
5. **Confirmed cases** are then ascertained, when test results or clinical diagnoses are completed.
6. Some patients are **hospitalized**.
7. Finally, **deaths** due to the illness are recorded.

Each level of the pyramid can be examined 
through many different data sources. 
For example, aggregated cell phone mobility data
could address population behavior, 
while the volume of certain Google search queries
might correlate with how many people have symptoms. 
Levels 4 through 7 of the pyramid are medically attended, 
and so can be examined using various medical records.
Confirmed cases and deaths are reported 
through local and state health authorities.

As we move from level 1 to level 7,
the data become more specific, 
since each level includes fewer people. 
The data also become less timely: level 1 
can be an *early indicator* of illness, 
since behavior can predict spread, 
but level 7 data only occurs after patients 
have already been infected and died. 
Only at level 5 do we actually 
gain data about diagnoses---data before level 5 is *syndromic*, 
meaning it can only relate to symptoms and behaviors.

Data streams that are organized in this way 
can be used for many possible purposes, including:

* **Forecasting.** Predicting where cases occur can help guide local responses;
  predicting hospitalization rates can help medical officials prepare.
* **Nowcasting.** If data can provide a clear picture of what's happening *right
  now*, this picture can be used to make decisions about re-opening criteria,
  resource allocation, closures, and so on.
* **Epidemiological research.** The data may help us understand what behaviors
  are linked to spread, what symptoms commonly occur, and other important
  questions to better understand the pandemic.

For each use case, researchers need quick access to reliable, up-to-date data streams. 
That's where the COVIDcast API comes in.



## Unique Data Sources

Delphi has built on its connections and reputation in influenza forecasting
to secure several sources of pandemic data that are unavailable anywhere else.
Our partners provide us with de-identified data, and our agreements with them
permit us to publish aggregated data in the COVIDcast API.
These data sources cover most levels of the severity pyramid and include:

* Massive surveys we conduct through Facebook: Facebook has been sending a
  random sample of its users to Delphi's symptoms and behavior survey every day
  since April 6. Our survey averages over 70,000 respondents each day, making
  it---along with its [international sister survey](https://covidmap.umd.edu/)
  run by University of Maryland---the largest public health survey ever conducted. 
  Our [previous blog post](https://delphi.cmu.edu/blog/2020/08/26/covid-19-symptom-surveys-through-facebook/)
  showed how the survey can indicate COVID-19 activity, 
  and preliminary analysis also suggests [it can help forecast COVID-19
  cases](https://delphi.cmu.edu/blog/2020/09/21/can-symptoms-surveys-improve-covid-19-forecasts/).
  See our [surveys site](https://covidcast.cmu.edu/surveys.html)
  for more on the survey, its questions, and getting access to data.
* Massive surveys we run through Google:
  From April 11 to May 14, Delphi conducted a single-question symptoms survey
  through Google. It reached well over 100,000 respondents daily during its 
  short run, and was a surprisingly effective measure 
  of pandemic activity preceding medical contact. For more, see our 
  [previous blog post](https://delphi.cmu.edu/blog/2020/09/18/covid-19-symptom-surveys-through-google/), 
  or our [technical documentation](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/google-survey.html).
  As explained in our past blog post, Delphi is currently considering new uses
  for these surveys.
* Insurance claims: Medical insurance claims include diagnostic codes,
  lab orders, and charge codes which can be used
  to estimate COVID-19 activity in a region.
  We have several partners who provide us with
  aggregate and line-level claims data,
  strictly de-identified to protect privacy.
  We use this data to construct signals
  reflecting COVID activity in [outpatient doctor's visits](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/doctor-visits.html)
  and in [hospital admissions](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/hospital-admissions.html).
* Quidel COVID antigen tests:
  Quidel is a national provider of networked lab testing devices,
  and began making de-identified records on COVID-19 antigen tests
  available to us in early May. Many public testing data sources only include
  PCR tests, not antigen tests, so this data fills an important gap.
  Our [technical documentation](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/quidel.html#covid-19-tests) gives more details.
* Google search trends:
  We query the Google Health Trends API
  for overall searcher interest in a set 
  of COVID-19 related terms about anosmia 
  (loss of smell or taste), 
  which emerged as a symptom of the coronavirus. 
  More details, including the specific search terms and topics we analyze,
  are available in our 
  [technical documentation](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/ght.html).

<!-- RJT: I'd suggest passing over this list and reorganizing it a bit. I would either do it: strictly in order of the severity pyramid, OR in order of the things we want to highlight the most. Currently it seems to do neither. If we go the latter route, I would describe the doctor's visits and hospital admissions signals RIGHT after the survey signals.

Few more comments: 
- We were linking to the technical documentation for most of the names of the signals here. I undid this, because I think a typical user will be expecting some nice readable explanation, and what they'll get is something very technical. So whenever we link to the technical documentation, I think we should flag it as such. Does this become too repetitive? I'm not sure. If we stick with it, then for consistency, we should apply it also to the medical claims paragraph (I did this in all other cases).
- What of the medical records paragraph? It seems odd because we're not linking or referring to any specific signals in particular. I guess primarily HealthJump data is based on medical records (perhaps entirely), but that's not online yet. Should we just cut this paragraph? 
- Should add a line somewhere here at the end that they should look out for future blog posts where we explore in more depth the uses of all these signals ... right? We do probably plan to follow-up on each one? 
- Finally, let's have Roni take a pass over this whole signal list and get his feedback. -->

We also host the following more widely-available signals in our API for the
convenience of the research community, and to provide revision tracking:

* Confirmed cases and deaths as reported by [JHU CSSE](https://github.com/CSSEGISandData/COVID-19).
* Confirmed cases and deaths as reported by [USAFacts](https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/).
* Mobility data as made available by
  [SafeGraph](https://docs.safegraph.com/docs/social-distancing-metrics);
  SafeGraph makes detailed de-identified data available to researchers, and by
  agreement with SafeGraph, we make county-level aggregates publicly available.

Nearly all our data streams are available 
at the county level across the United States. 
We also aggregate our signals to metropolitan statistical areas and states. 
For a full list of all data streams, see our 
[COVIDcast signal documentation
site](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_signals.html).
The software we've developed to obtain and aggregate this data is open-source,
shared in our [covidcast-indicators GitHub
repository](https://github.com/cmu-delphi/covidcast-indicators).

All of the above data streams are made publicly available 
through our COVIDcast API---if you're interested 
in using these signals for research 
or to understand trends in your area, 
pulling the data is only a moment's work. 
Let's discuss how the data is stored and how you can get access.

## Tracking Observations and Revisions

Each record in our API is an observation covering 
a set of events aggregated by time and by region.
Most signals in the API are calculated daily,
but some are calculated weekly,
so we tend to keep the official definitions general. 
Each record thus includes:

* `time_value`: The time period when the events occurred.
* `geo_value`: The geographic region where the events occurred.
* `value`: The aggregate value.
* `stderr`: The standard error.
* `sample_size`: The number of events making up the aggregation.

For example, a number of COVID-19 antigen tests 
were performed in the state of New York on August 1. 
The `time_value` would be August 1, 
with `geo_value` indicating the state of New York,
while the remaining fields would give the estimated test positivity rate 
(the percentage of tests that were positive for COVID-19), 
its standard error, and the number of tests used to calculate the estimate.

But crucially---and unlike most other sources of COVID-19 data---our API reports
two additional fields with each record:

* `issue`: The time period when this observation was published.
* `lag`: The time delay between when the events occurred and when this
  observation was published.

For example, results of COVID-19 antigen tests may take 
between four days and six weeks to reach us, 
depending on the technology and staff available at each testing site. 
We might publish our first estimate 
of August 1st's test positivity rate on August 6th,
giving an issue date of August 6 and lag of five days.

But when more data about August 1st's tests arrive the next day, 
we issue a second estimate with an issue date of August 7. 
Each record remains in the API, permitting users to see the changes 
and ask "What was known *as of* this date?"
This is important because estimates 
can change for *weeks* as new data arrives:

```{r q-versioning, warning=FALSE, message=FALSE, cache=TRUE}
library(covidcast)
library(dplyr)
query_date <- "2020-08-01"
covidcast_signal(
  data_source = "quidel",
  signal = "covid_ag_raw_pct_positive",
  start_day = query_date,
  end_day = query_date,
  geo_type = "state",
  geo_value = "ny",
  issues = c(query_date, "2020-09-04")) %>%
    select(time_value, value, sample_size, issue, lag) %>%
    distinct(value, .keep_all=TRUE) %>%
    knitr::kable("html", digits = 2,
                 col.names = c("Test date", "Positivity rate (%)", "Sample size",
                               "Issued on", "Lag (days)"))
```

Many other data sources are also subject to revisions:

* Case and death counts are frequently corrected or adjusted by authorities.
* Medical claims data can take weeks to be submitted and processed.
* Lab tests and medical records can be backlogged for a variety of reasons.
* Surveys are not always completed promptly.

An accurate revision log is crucial for researchers 
building forecasts of COVID-19 cases or outcomes. 
A forecast that is made today can only rely 
on information we have access to today. 
Forecasting models are often developed by building them 
to predict cases using historical data---but to do so, 
the model must use only data that was available on the forecast date,
not the updates that would only arrive later. 

Our engineering team has worked to enable revision tracking for all data sources
we ingest, including from third parties who do not track revisions themselves.
This ensures users can always request the data as it was known on a specific
date, and preserves the history of changes for future analysis.

## Accessing the API

A massive database of COVID-19 data is, of course, 
of no use if nobody can access it. 
We provide several ways to access COVIDcast data.

First, the [public COVIDcast map](https://covidcast.cmu.edu/) 
provides a selection of our signals, 
and includes an "Export Data" tab that can 
pull a selected signal and download it as a CSV. 
Browse the map to choose which signal you are interested in, 
then use Export Data to obtain the data for further analysis.

For more advanced users, we provide R and Python packages
to make access to the data easy 
for anyone already conducting 
data analysis in either language. Suppose, for example, that you browse the
[COVIDcast signal
documentation](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_signals.html)
and decide you would like to conduct an analysis of a Hospital Admissions
signal. According to [its documentation
page](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/hospital-admissions.html),
this source is called `hospital-admissions`, and there are several available
signals to choose from. Reviewing the technical details, you decide
`smoothed_adj_covid19` fits your needs best, because it removes day-of-week
effects. With the source and signal names in hand, you can quickly pull the data.

For example, an R user can install our 
[covidcast package](https://cmu-delphi.github.io/covidcast/covidcastR/) 
and then quickly plot the percentage of hospital admissions 
that are due to COVID-19 in several states. 
(Click the "Code" button to see the R code used to produce this example.)

```{r dv-graph, message=FALSE, cache=TRUE}
library(covidcast)
hosp <- covidcast_signal(
    data_source = "hospital-admissions", signal = "smoothed_adj_covid19",
    start_day = "2020-03-01", end_day = "2020-08-30",
    geo_type = "state", geo_values = c("pa", "ny", "tx")
)
plot(hosp, plot_type = "line",
     title = "% of hospital admissions due to COVID-19")
```

Since the packages also support mapping, 
we can also examine the percentage 
of outpatient doctor's visits 
due to COVID-like illness in the South.

```{r dv-maps, message=FALSE, cache=TRUE, fig.width=10}
library(gridExtra)
dv <- covidcast_signal(
    data_source = "doctor-visits", signal = "smoothed_adj_cli",
    start_day = "2020-07-15", end_day = "2020-08-24")
south <- c("md", "de", "va", "wv", "ky", "tn", "nc", "sc", "fl", "ga", "al",
           "ms", "la", "ar", "tx", "ok")
g1 <- plot(dv, time_value = "2020-07-15", include = south,
           title = "% of doctor's visits due to CLI on July 15")
g2 <- plot(dv, time_value = "2020-08-24", include = south,
           title = "% of doctor's visits due to CLI on August 24")
grid.arrange(g1, g2, nrow = 1)
```

In Python, fetching data requires the 
[covidcast package](https://cmu-delphi.github.io/covidcast/covidcast-py/html/),
which can quickly produce a Pandas data frame. 
For example, here we fetch the estimated percentage 
of people in each state who know someone who is sick, 
based on Delphi's [symptom
surveys](https://delphi.cmu.edu/blog/2020/08/26/covid-19-symptom-surveys-through-facebook/).
According to the [relevant documentation
page](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/hospital-admissions.html),
this is the `fb-survey` data source's `smoothed_hh_cmnty_cli` signal.
(Click the "Code" button to see the Python code used to produce this example.)

```{python python-data, dev='svg'}
import covidcast
from datetime import date
import matplotlib.pyplot as plt

data = covidcast.signal("fb-survey", "smoothed_hh_cmnty_cli",
                        date(2020, 9, 8), date(2020, 9, 8),
                        geo_type="state")
covidcast.plot_choropleth(data, figsize=(12, 10))
plt.title("% who know someone who is sick, Sept 8, 2020")
```

Each package's documentation gives numerous other examples of pulling, plotting,
and mapping data from our API. (Note that the Export Data feature in the map can
also show you example R or Python code to download any signal from the map.)
Both packages support querying the latest version of data---as shown above---but
can also fetch prior revisions or only the information that was available on a
certain date.

But R and Python are not required for access to our data. Users can simply make
HTTP requests to a specific query URL and receive data back in JSON form. By
setting `data_source`, `signal`, `time_type`, `geo_type`, `time_values`, and
`geo_value` arguments in the URL, you can select the specific data source you
want and the regions and times you want it for. For example, the URL

```
https://api.covidcast.cmu.edu/epidata/api.php?source=covidcast&data_source=fb-survey&signal=raw_cli&time_type=day&geo_type=county&time_values=20200406-20200410&geo_value=06001
```

fetches the `raw_cli` signal from the `fb-survey` source---representing the
estimated percent of people with COVID-like illness based on our symptom
surveys---for one county in the United States between April 6 and April
10, 2020. That county is Alameda County, CA, which has the FIPS code 06001.

Query syntax is defined on our [API documentation
site](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html), and you
can use any programming language that supports making HTTP requests---which is
most programming languages---to fetch up-to-date data.

## Putting the API to Work

The [COVIDcast API](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html) 
provides unified access to numerous COVID data streams,
which can be browsed through our [interactive map](https://covidcast.cmu.edu/) 
and easily accessed through our 
[R and Python packages](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_clients.html).
Unlike most other sources of COVID data,
it tracks the complete revision history of every signal, 
allowing historical reconstructions of
what information was available at specific times. 
And many of its data streams simply 
aren't available anywhere else.

We invite you to put the API to use for your own purposes. 
Building a dashboard for your community? 
Testing out forecasting methods? 
Studying how the pandemic evolves? 
We might have the data you're looking for.

Many of our data streams are already being used to inform decision-making. 
For example, [COVID Exit Strategy](https://www.covidexitstrategy.org/) 
tracks the pandemic and whether states are ready to reopen, 
using symptom survey data from the COVIDcast API as a key data source. 
Anthem's [C19 Explorer](https://c19explorer.io/) 
presents a comprehensive community picture of the pandemic, 
including outpatient doctor's visit data from COVIDcast. 
Aledade's [COVID-19 Interactive Map](https://covidmap.aledade.com/) 
applies scan statistics algorithms to COVIDcast survey data 
to detect statistically significant clusters.

We hope to see you join this list soon!

**Acknowledgments.** *The COVIDcast API builds on the Epidata API, built by
Delphi founding member David Farrow. Kathryn Mazaitis leads Delphi's engineering
team, overseeing the COVIDcast API and all related operations. Brian Clark
manages the API infrastructure, with significant help from Wael Al Saeed, Eu
Jing Chua, Samuel Gratzl, and George Haff. Alex Reinhart maintains the COVIDcast
API clients, with major contributions from Andrew Chin and Ryan Tibshirani. Ryan
and Roni Rosenfeld secured many data partnerships, with key support from CMU's
legal team. Last but not least, building the COVIDcast signals themselves was
(and still is) a huge team effort: many Delphi members contributed code and
expertise to ingest and serve data on the COVIDcast API, including Aaron Rumack,
Addison Hu, Eu Jing Chua, James Sharpnack, Jeremy Weiss, Jimi Kim, Jingjing
Tang, Larry Wasserman, Lester Mackey, Logan Brooks, Maria Jahja, Natalia
Lombardi de Oliveira, Noah Simon, Pratik Patil, Robert and Ryan Tibshirani, Roni
Rosenfeld, Samyak Rajanala, Sangwon Hyun, Taylor Arnold, Valérie Ventura, and
Zachary Lipton.*

---

*[Kathryn Mazaitis](https://cs.cmu.edu/~krivard) manages Delphi's engineering 
team, and is a Senior Research Programmer in the Machine Learning Department at 
CMU.*

*[Alex Reinhart](https://www.refsmmat.com) manages Delphi's surveys, and is an
Assistant Teaching Professor in the Department of Statistics & Data Science at
CMU.*

